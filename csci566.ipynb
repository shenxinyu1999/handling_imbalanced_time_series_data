{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aN-rSMQz6zWd",
        "outputId": "8caa897a-5d56-43e9-cce0-79ab86f0aebe"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# data file path and names\n",
        "data_file_path = '/content/gdrive/MyDrive/data/'\n",
        "\n",
        "print(\"Google Drive Mounted\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_file_path = 'data/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kqr4UGQky-pF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "Z3PZRhpM-nic",
        "outputId": "c89b8fa1-5700-4bea-a6f0-ecdd2f538207"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>BirthYear</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Parkinsons</th>\n",
              "      <th>Tremors</th>\n",
              "      <th>DiagnosisYear</th>\n",
              "      <th>Sided</th>\n",
              "      <th>UPDRS</th>\n",
              "      <th>Impact</th>\n",
              "      <th>Levadopa</th>\n",
              "      <th>DA</th>\n",
              "      <th>MAOB</th>\n",
              "      <th>Other</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0EA27ICBLF</th>\n",
              "      <td>1952</td>\n",
              "      <td>Female</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>2000</td>\n",
              "      <td>Left</td>\n",
              "      <td>Don't know</td>\n",
              "      <td>Severe</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0QAZFRHQHW</th>\n",
              "      <td>1959</td>\n",
              "      <td>Female</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>------</td>\n",
              "      <td>None</td>\n",
              "      <td>Don't know</td>\n",
              "      <td>------</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0WTDIGPSBZ</th>\n",
              "      <td>1946</td>\n",
              "      <td>Female</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>------</td>\n",
              "      <td>None</td>\n",
              "      <td>Don't know</td>\n",
              "      <td>------</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1HOEBIGASW</th>\n",
              "      <td>1944</td>\n",
              "      <td>Male</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>------</td>\n",
              "      <td>None</td>\n",
              "      <td>Don't know</td>\n",
              "      <td>------</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1WMVCCU4RH</th>\n",
              "      <td>1953</td>\n",
              "      <td>Male</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>2017</td>\n",
              "      <td>Left</td>\n",
              "      <td>Don't know</td>\n",
              "      <td>Medium</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           BirthYear  Gender Parkinsons Tremors DiagnosisYear Sided  \\\n",
              "0EA27ICBLF      1952  Female       True    True          2000  Left   \n",
              "0QAZFRHQHW      1959  Female      False   False        ------  None   \n",
              "0WTDIGPSBZ      1946  Female      False   False        ------  None   \n",
              "1HOEBIGASW      1944    Male      False   False        ------  None   \n",
              "1WMVCCU4RH      1953    Male       True    True          2017  Left   \n",
              "\n",
              "                 UPDRS   Impact Levadopa     DA   MAOB  Other  \n",
              "0EA27ICBLF  Don't know   Severe     True   True  False  False  \n",
              "0QAZFRHQHW  Don't know   ------    False  False  False  False  \n",
              "0WTDIGPSBZ  Don't know   ------    False  False  False  False  \n",
              "1HOEBIGASW  Don't know   ------    False  False  False  False  \n",
              "1WMVCCU4RH  Don't know   Medium    False  False  False  False  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rows = []\n",
        "colNames = ['BirthYear','Gender','Parkinsons','Tremors','DiagnosisYear','Sided','UPDRS','Impact','Levadopa','DA','MAOB','Other']\n",
        "users = []\n",
        "\n",
        "userFolder = data_file_path + 'Users'\n",
        "\n",
        "for userFilename in os.listdir(userFolder):\n",
        "    users.append(userFilename[5:-4])\n",
        "\n",
        "    f = open(os.path.join(userFolder, userFilename))\n",
        "    lines = f.readlines()\n",
        "\n",
        "    row = []\n",
        "    col = []\n",
        "\n",
        "    for line in lines:\n",
        "        line = line[:-1]\n",
        "        lineSplit = line.split(': ')\n",
        "        \n",
        "        row.append(lineSplit[1])\n",
        "        col.append(lineSplit[0])\n",
        "            \n",
        "    if col == colNames:\n",
        "        rows.append(row)\n",
        "    else:\n",
        "        print(userFilename+'read wrong.')\n",
        "\n",
        "    f.close()\n",
        "\n",
        "userDF = pd.DataFrame(rows, columns=colNames, index=users)\n",
        "userDF.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "1IdfTVASi8pR",
        "outputId": "349eb47a-c761-4463-e453-6b1ac50e1502"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1354, 0, 0, 7, 0, 0, 0, 0, 0]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UserID</th>\n",
              "      <th>Date</th>\n",
              "      <th>Timestamp</th>\n",
              "      <th>Hand</th>\n",
              "      <th>HoldTime</th>\n",
              "      <th>Direction</th>\n",
              "      <th>LatencyTime</th>\n",
              "      <th>FlightTime</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0EA27ICBLF</td>\n",
              "      <td>160722</td>\n",
              "      <td>18:41:04.336</td>\n",
              "      <td>L</td>\n",
              "      <td>0101.6</td>\n",
              "      <td>LL</td>\n",
              "      <td>0234.4</td>\n",
              "      <td>0156.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0EA27ICBLF</td>\n",
              "      <td>160722</td>\n",
              "      <td>18:42:14.070</td>\n",
              "      <td>L</td>\n",
              "      <td>0085.9</td>\n",
              "      <td>LL</td>\n",
              "      <td>0437.5</td>\n",
              "      <td>0359.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0EA27ICBLF</td>\n",
              "      <td>160722</td>\n",
              "      <td>18:42:14.273</td>\n",
              "      <td>L</td>\n",
              "      <td>0078.1</td>\n",
              "      <td>LL</td>\n",
              "      <td>0210.9</td>\n",
              "      <td>0125.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0EA27ICBLF</td>\n",
              "      <td>160722</td>\n",
              "      <td>18:42:14.617</td>\n",
              "      <td>L</td>\n",
              "      <td>0062.5</td>\n",
              "      <td>LL</td>\n",
              "      <td>0359.4</td>\n",
              "      <td>0281.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0EA27ICBLF</td>\n",
              "      <td>160722</td>\n",
              "      <td>18:42:15.586</td>\n",
              "      <td>S</td>\n",
              "      <td>0125.0</td>\n",
              "      <td>LS</td>\n",
              "      <td>0187.5</td>\n",
              "      <td>0093.8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       UserID    Date     Timestamp Hand HoldTime Direction LatencyTime  \\\n",
              "0  0EA27ICBLF  160722  18:41:04.336    L   0101.6        LL      0234.4   \n",
              "1  0EA27ICBLF  160722  18:42:14.070    L   0085.9        LL      0437.5   \n",
              "2  0EA27ICBLF  160722  18:42:14.273    L   0078.1        LL      0210.9   \n",
              "3  0EA27ICBLF  160722  18:42:14.617    L   0062.5        LL      0359.4   \n",
              "4  0EA27ICBLF  160722  18:42:15.586    S   0125.0        LS      0187.5   \n",
              "\n",
              "  FlightTime  \n",
              "0     0156.3  \n",
              "1     0359.4  \n",
              "2     0125.0  \n",
              "3     0281.3  \n",
              "4     0093.8  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rows = []\n",
        "colNames = ['UserID','Date','Timestamp','Hand','HoldTime','Direction','LatencyTime','FlightTime']\n",
        "\n",
        "dataFolder = data_file_path + 'TappyData'\n",
        "invalid = [0,0,0,0,0,0,0,0,0]\n",
        "for dataFilename in os.listdir(dataFolder):\n",
        "    infoArr = dataFilename[:-4].split('_')\n",
        "    userID = infoArr[0]\n",
        "    yearMonth = infoArr[1]\n",
        "\n",
        "    f = open(os.path.join(dataFolder, dataFilename))\n",
        "    lines = f.readlines()\n",
        "\n",
        "    row = []\n",
        "    \n",
        "    for idx, line in enumerate(lines):\n",
        "        line = line[:-1]\n",
        "        lineSplit = line.split('\\t')\n",
        "\n",
        "        if len(line) != 57:\n",
        "            invalid[0] = invalid[0] + 1\n",
        "        elif len(lineSplit[0]) != 10 or lineSplit[0] != userID:\n",
        "            invalid[1] = invalid[1] + 1\n",
        "        elif len(lineSplit[1]) != 6 or lineSplit[1][0:4] != yearMonth:\n",
        "            invalid[2] = invalid[2] + 1\n",
        "        elif len(lineSplit[2]) != 12: # Timestamp\n",
        "            invalid[3] = invalid[3] + 1\n",
        "        elif len(lineSplit[3]) != 1: # Hand\n",
        "            invalid[4] = invalid[4] + 1\n",
        "        elif len(lineSplit[4]) != 6: # HoldTime\n",
        "            invalid[5] = invalid[5] + 1\n",
        "        elif len(lineSplit[5]) != 2: # Direction\n",
        "            invalid[6] = invalid[6] + 1\n",
        "        elif len(lineSplit[6]) != 6: # LatencyTime\n",
        "            invalid[7] = invalid[7] + 1\n",
        "        elif len(lineSplit[7]) != 6: # FlightTime\n",
        "            invalid[8] = invalid[8] + 1\n",
        "        else:\n",
        "            rows.append(lineSplit[:-1])\n",
        "    \n",
        "    f.close()\n",
        "print(invalid)\n",
        "dataDF = pd.DataFrame(rows, columns=colNames)\n",
        "dataDF.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ohW0SBwkpMgG"
      },
      "outputs": [],
      "source": [
        "df = pd.merge(dataDF,userDF[['Parkinsons']], left_on='UserID', right_index=True, how='left')\n",
        "df['Parkinsons'] = df['Parkinsons'].map({'False':0, 'True':1})\n",
        "df['Hand'] = df['Hand'].map({'L':1, 'R':2, 'S':0})\n",
        "df['Direction'] = df['Direction'].map({'LL':0, 'RL':1, 'LR':2, 'RR':3, 'LS':4, 'SL':5, 'RS':6, 'SR':7, 'SS':8})\n",
        "df['HoldTime'] = df['HoldTime'].astype(float)\n",
        "df['LatencyTime'] = df['LatencyTime'].astype(float)\n",
        "df['FlightTime'] = df['FlightTime'].astype(float)\n",
        "df = df.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "mqpCZClr6aQJ"
      },
      "outputs": [],
      "source": [
        "positiveSamples = df[df['Parkinsons']==1]\n",
        "negativeSamples = df[df['Parkinsons']==0]\n",
        "positiveGrouped = positiveSamples.groupby('UserID')\n",
        "negativeGrouped = negativeSamples.groupby('UserID')\n",
        "positiveUserIDs = np.array(positiveSamples['UserID'].unique())\n",
        "negativeUserIDs = np.array(negativeSamples['UserID'].unique())\n",
        "np.random.shuffle(positiveUserIDs)\n",
        "np.random.shuffle(negativeUserIDs)\n",
        "\n",
        "train_ratio = 0.7\n",
        "valid_ratio = 0.2\n",
        "\n",
        "total_positive_rows = len(positiveSamples)\n",
        "train_positive_rows = int(total_positive_rows * train_ratio)\n",
        "valid_positive_rows = int(total_positive_rows * valid_ratio)\n",
        "total_negative_rows = len(negativeSamples)\n",
        "train_negative_rows = int(total_negative_rows * train_ratio)\n",
        "valid_negative_rows = int(total_negative_rows * valid_ratio)\n",
        "\n",
        "# Initialize empty DataFrames for training, validation, and testing sets\n",
        "train_df = pd.DataFrame(columns=df.columns)\n",
        "valid_df = pd.DataFrame(columns=df.columns)\n",
        "test_df = pd.DataFrame(columns=df.columns)\n",
        "\n",
        "train_positive_count, valid_positive_count = 0, 0\n",
        "train_negative_count, valid_negative_count = 0, 0\n",
        "train_data = []\n",
        "valid_data = []\n",
        "test_data = []\n",
        "\n",
        "# Iterate over the shuffled user_ids and assign rows to the corresponding set\n",
        "for userID in positiveUserIDs:\n",
        "    user_data = positiveGrouped.get_group(userID)\n",
        "    user_rows = len(user_data)\n",
        "    \n",
        "    if train_positive_count + user_rows <= train_positive_rows:\n",
        "        train_data.append(user_data)\n",
        "        train_positive_count += user_rows\n",
        "    elif valid_positive_count + user_rows <= valid_positive_rows:\n",
        "        valid_data.append(user_data)\n",
        "        valid_positive_count += user_rows\n",
        "    else:\n",
        "        test_data.append(user_data)\n",
        "\n",
        "for userID in negativeUserIDs:\n",
        "    user_data = negativeGrouped.get_group(userID)\n",
        "    user_rows = len(user_data)\n",
        "    \n",
        "    if train_negative_count + user_rows <= train_negative_rows:\n",
        "        train_data.append(user_data)\n",
        "        train_negative_count += user_rows\n",
        "    elif valid_negative_count + user_rows <= valid_negative_rows:\n",
        "        valid_data.append(user_data)\n",
        "        valid_negative_count += user_rows\n",
        "    else:\n",
        "        test_data.append(user_data)\n",
        "\n",
        "train_df = pd.concat(train_data)\n",
        "valid_df = pd.concat(valid_data)\n",
        "test_df = pd.concat(test_data)\n",
        "valid_test_df = pd.concat([valid_df, test_df]).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "import torch\n",
        "device = \"cuda\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "xs03fa4Ip-r3"
      },
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(4, 1024)\n",
        "        self.fc2 = nn.Linear(1024, 128)\n",
        "        self.fc3 = nn.Linear(128, 32)\n",
        "        self.fc4 = nn.Linear(32, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = nn.functional.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = nn.functional.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        x = nn.functional.relu(x)\n",
        "        x = self.fc4(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "MJYrMgTJ7Lht"
      },
      "outputs": [],
      "source": [
        "feature_columns = ['Hand','HoldTime','Direction','LatencyTime']\n",
        "label_column = 'Parkinsons'\n",
        "\n",
        "X_train = torch.tensor(train_df[feature_columns].values, dtype=torch.float32).to(device)\n",
        "y_train = torch.tensor(train_df[label_column].values, dtype=torch.float32).unsqueeze(1).to(device)\n",
        "\n",
        "X_valid = torch.tensor(valid_df[feature_columns].values, dtype=torch.float32).to(device)\n",
        "y_valid = torch.tensor(valid_df[label_column].values, dtype=torch.float32).unsqueeze(1).to(device)\n",
        "\n",
        "X_test = torch.tensor(test_df[feature_columns].values, dtype=torch.float32).to(device)\n",
        "y_test = torch.tensor(test_df[label_column].values, dtype=torch.float32).unsqueeze(1).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXRjypXgtlSH",
        "outputId": "8ae014d9-6399-4b3f-f094-d9d255ed4e09"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196612/196612 [06:33<00:00, 500.05it/s]\n",
            "100%|██████████| 44254/44254 [00:29<00:00, 1492.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 train loss: 0.018 val loss: 1.401\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196612/196612 [06:26<00:00, 508.14it/s]\n",
            "100%|██████████| 44254/44254 [00:29<00:00, 1486.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 train loss: 0.018 val loss: 1.671\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196612/196612 [06:26<00:00, 508.86it/s]\n",
            "100%|██████████| 44254/44254 [00:29<00:00, 1487.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 train loss: 0.018 val loss: 1.397\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196612/196612 [06:38<00:00, 493.39it/s]\n",
            "100%|██████████| 44254/44254 [00:31<00:00, 1417.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 train loss: 0.018 val loss: 1.576\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196612/196612 [06:37<00:00, 495.24it/s]\n",
            "100%|██████████| 44254/44254 [00:31<00:00, 1427.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5 train loss: 0.018 val loss: 1.501\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196612/196612 [06:34<00:00, 498.23it/s]\n",
            "100%|██████████| 44254/44254 [00:31<00:00, 1424.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6 train loss: 0.018 val loss: 1.543\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196612/196612 [06:35<00:00, 496.94it/s]\n",
            "100%|██████████| 44254/44254 [00:30<00:00, 1431.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7 train loss: 0.018 val loss: 1.554\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196612/196612 [06:36<00:00, 495.43it/s]\n",
            "100%|██████████| 44254/44254 [00:31<00:00, 1383.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8 train loss: 0.018 val loss: 1.627\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196612/196612 [06:26<00:00, 508.53it/s]\n",
            "100%|██████████| 44254/44254 [00:30<00:00, 1449.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9 train loss: 0.018 val loss: 1.575\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196612/196612 [06:21<00:00, 515.97it/s]\n",
            "100%|██████████| 44254/44254 [00:30<00:00, 1449.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10 train loss: 0.018 val loss: 1.451\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 40812/40812 [00:47<00:00, 864.75it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True positives: 633086\n",
            "True negatives: 22503\n",
            "False positives: 636308\n",
            "False negatives: 14077\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_dataset = TensorDataset(X_valid, y_valid)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=32)\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=32)\n",
        "\n",
        "model = MLP().to(device)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "# Train the MLP model on the training set and evaluate on the validation set\n",
        "best_loss = float('inf')\n",
        "for epoch in range(10):\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in tqdm(train_dataloader):\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    # Evaluate the model on the validation set\n",
        "    with torch.no_grad():\n",
        "        total_val_loss = 0\n",
        "        for inputs, labels in tqdm(val_dataloader):\n",
        "            val_outputs = model(inputs)\n",
        "            val_loss = criterion(val_outputs, labels)\n",
        "            total_val_loss = total_val_loss + val_loss\n",
        "        if total_val_loss < best_loss:\n",
        "            best_loss = total_val_loss\n",
        "            best_model = model.state_dict()\n",
        "    print('Epoch %d train loss: %.3f val loss: %.3f' % (epoch + 1, running_loss / len(X_train), total_val_loss))\n",
        "\n",
        "# Load the best model and evaluate it on the testing set\n",
        "model.load_state_dict(best_model)\n",
        "with torch.no_grad():\n",
        "    test_tp = test_tn = test_fp = test_fn = 0\n",
        "    for inputs, labels in tqdm(test_dataloader):\n",
        "        test_outputs = model(inputs)\n",
        "        test_predictions = (test_outputs > 0.5).float()\n",
        "        test_tp = test_tp + ((test_predictions == 1) & (labels == 1)).sum().item()\n",
        "        test_tn = test_tn + ((test_predictions == 0) & (labels == 0)).sum().item()\n",
        "        test_fp = test_fp + ((test_predictions == 1) & (labels == 0)).sum().item()\n",
        "        test_fn = test_fn + ((test_predictions == 0) & (labels == 1)).sum().item()\n",
        "    \n",
        "print('True positives:', test_tp)\n",
        "print('True negatives:', test_tn)\n",
        "print('False positives:', test_fp)\n",
        "print('False negatives:', test_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-gGskZwqhG1"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), '/content/gdrive/MyDrive/model.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "hHhMB9pgyyxu"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.03415698887844921"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZk4c706BqR4"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "feature_columns = ['HoldTime'] # ['Hand','HoldTime','Direction','LatencyTime']\n",
        "label_column = 'Parkinsons'\n",
        "X_train = train_df[feature_columns]\n",
        "y_train = train_df[label_column]\n",
        "\n",
        "X_test = valid_test_df[feature_columns]\n",
        "y_test = valid_test_df[label_column]\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "svm = LinearSVC(verbose=2,max_iter=1000,C=0.01)\n",
        "svm.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_test_pred = svm.predict(X_test_scaled)\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "print(f'Test accuracy: {test_accuracy:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "agCz6gqb0ldC"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, y_test_pred)\n",
        "tn, fp, fn, tp = cm.ravel()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "6cd27dcb146ec26177318fc2de7219250640a76b7da8252aaf504d9c7a582fb2"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
